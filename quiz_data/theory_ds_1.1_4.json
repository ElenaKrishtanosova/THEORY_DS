{
  "quiz_title": "K-nearest neighbour algorithm (KNN) ",
  "questions": [
    {
      "question_id": 1,
      "question_text": "Почему KNN называют 'ленивым' алгоритмом?",
      "question_type": "single_choice",
      "options": [
        "Потому что он медленно обучается",
        "Он не строит явную модель во время обучения",
        "Требует мало вычислительных ресурсов",
        "Игнорирует выбросы в данных"
      ],
      "correct_answer": 1,
      "explanation": "KNN не обучается явно во время тренировочной фазы - он просто запоминает данные. Все вычисления происходят на этапе предсказания."
    },
    {
      "question_id": 2,
      "question_text": "Какая из метрик расстояния НЕ подходит для категориальных признаков?",
      "question_type": "single_choice",
      "options": [
        "Евклидово расстояние",
        "Расстояние Хэмминга",
        "Расстояние Джаккарда",
        "Косинусное расстояние"
      ],
      "correct_answer": 0,
      "explanation": "Евклидово расстояние работает только с числовыми признаками. Для категориальных используют Хэмминг (совпадение значений) или Джаккард (сходство множеств)."
    },
    {
      "question_id": 3,
      "question_text": "Как выбор четного K может повлиять на бинарную классификацию?",
      "question_type": "single_choice",
      "options": [
        "Увеличит скорость работы алгоритма",
        "Может привести к 'ничьей' между классами",
        "Уменьшит влияние выбросов",
        "Автоматически выберет класс с большим весом"
      ],
      "correct_answer": 1,
      "explanation": "При четном K может возникнуть ситуация, когда голоса разделятся поровну (K/2 vs K/2). Поэтому обычно берут нечетные значения K."
    },
    {
      "question_id": 4,
      "question_text": "Какие из следующих утверждений о масштабировании признаков верны? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "KNN требует масштабирования из-за чувствительности к разным диапазонам признаков",
        "Нормализация улучшает интерпретируемость коэффициентов",
        "Метрики расстояния доминируются признаками с большими значениями без масштабирования",
        "Достаточно масштабировать только категориальные признаки"
      ],
      "correct_answers": [0, 2],
      "explanation": "KNN критически зависит от масштабов признаков, так как использует расстояния. Признаки с большим диапазоном будут доминировать в метрике без нормализации."
    },
    {
      "question_id": 5,
      "question_text": "Как влияет увеличение K на границу решения в KNN?",
      "question_type": "single_choice",
      "options": [
        "Граница становится более сложной и зазубренной",
        "Граница сглаживается, уменьшается variance",
        "Не влияет на форму границы",
        "Приводит к линейной границе решения"
      ],
      "correct_answer": 1,
      "explanation": "Большие значения K делают границу более гладкой, уменьшая переобучение (variance), но могут увеличить bias."
    },
    {
      "question_id": 6,
      "question_text": "Почему KNN плохо работает с данными высокой размерности?",
      "question_type": "single_choice",
      "options": [
        "Из-за проклятия размерности - точки становятся слишком далекими",
        "Требует экспоненциально больше памяти",
        "Не может вычислять расстояния в многомерных пространствах",
        "Становится слишком чувствительным к шуму"
      ],
      "correct_answer": 0,
      "explanation": "В высокоразмерных пространствах все точки становятся примерно равноудаленными (проклятие размерности), что делает понятие 'ближайших соседей' бессмысленным."
    },
    {
      "question_id": 7,
      "question_text": "Какие из методов ускорения KNN верны? (Выберите 3)",
      "question_type": "multi_choice",
      "options": [
        "Использование KD-деревьев для поиска соседей",
        "Применение PCA для уменьшения размерности",
        "Хеширование с учетом местоположения (LSH)",
        "Увеличение значения K",
        "Использование только евклидовой метрики"
      ],
      "correct_answers": [0, 1, 2],
      "explanation": "KD-деревья, уменьшение размерности и LSH - эффективные методы ускорения KNN. Большие K замедляют предсказание, а ограничение метрики не всегда ускоряет работу."
    },
    {
      "question_id": 8,
      "question_text": "Как обрабатываются вещественные признаки в Weighted KNN?",
      "question_type": "single_choice",
      "options": [
        "Близкие соседи получают больший вес",
        "Признаки с большей дисперсией получают больший вес",
        "Все соседи голосуют с равным весом",
        "Только ближайший сосед определяет класс"
      ],
      "correct_answer": 0,
      "explanation": "В Weighted KNN вес голоса соседа обратно пропорционален расстоянию до классифицируемой точки - ближайшие соседи влияют сильнее."
    },
    {
      "question_id": 9,
      "question_text": "Какая проблема возникает при использовании KNN с несбалансированными классами?",
      "question_type": "single_choice",
      "options": [
        "Доминирующий класс будет чаще выбираться как предсказание",
        "Алгоритм становится слишком медленным",
        "Теряется интерпретируемость модели",
        "Нельзя использовать категориальные признаки"
      ],
      "correct_answer": 0,
      "explanation": "При несбалансированных данных ближайшие соседи чаще будут принадлежать доминирующему классу. Решения: взвешивание, oversampling/undersampling."
    },
    {
      "question_id": 10,
      "question_text": "Как выбрать оптимальное K методом локтя?",
      "question_type": "single_choice",
      "options": [
        "Найти K с минимальной ошибкой на тестовых данных",
        "Выбрать K в точке изгиба кривой ошибки",
        "Взять K равным корню из числа наблюдений",
        "Использовать кросс-валидацию для всех K"
      ],
      "correct_answer": 1,
      "explanation": "Метод локтя ищет точку на графике ошибки, где дальнейшее увеличение K не дает значительного улучшения (изгиб кривой)."
    }
  ],
  "pdf_links": [
    "https://drive.google.com/file/d/10Z7Sszk22ho980dqMUl9T8tViVrqYjBi/view?usp=sharing",
    "https://drive.google.com/file/d/10Z7Sszk22ho980dqMUl9T8tViVrqYjBi/view?usp=sharing",
    "https://drive.google.com/file/d/10Z7Sszk22ho980dqMUl9T8tViVrqYjBi/view?usp=sharing"
  ],
  "metadata": {
    "difficulty_level": "advanced",
    "tags": ["knn", "distance_metrics", "curse_of_dimensionality", "scaling", "model_selection"],
    "author": "ML Expert",
    "created_at": "2024-02-05"
  }
}