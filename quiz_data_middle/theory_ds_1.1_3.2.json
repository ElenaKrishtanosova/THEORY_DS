{
  "quiz_title": "Decision Trees (Ensembles - Random Forest)",
  "questions": [
    {
      "question_id": 1,
      "question_text": "Почему Random Forest обычно работает лучше, чем одно дерево решений?",
      "question_type": "single_choice",
      "options": [
        "Потому что использует больше признаков",
        "За счет усреднения предсказаний многих деревьев",
        "Потому что деревья в RF всегда глубже",
        "За счет использования только линейных зависимостей"
      ],
      "correct_answer": 1,
      "explanation": "RF объединяет предсказания множества деревьев, что уменьшает переобучение и делает модель более устойчивой. Это называется ансамблевым методом."
    },
    {
      "question_id": 2,
      "question_text": "Как Random Forest создает разнообразие между деревьями? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Используя разные подмножества данных для каждого дерева",
        "Применяя разные алгоритмы для каждого дерева",
        "Выбирая случайные подмножества признаков",
        "Используя только категориальные признаки"
      ],
      "correct_answers": [0, 2],
      "explanation": "RF создает разнообразие через: 1) Бутстрап выборки (разные данные для каждого дерева) 2) Случайный выбор подмножества признаков для разбиений."
    },
    {
      "question_id": 3,
      "question_text": "Что такое Out-of-Bag (OOB) оценка в Random Forest?",
      "question_type": "single_choice",
      "options": [
        "Оценка качества на специальном тестовом наборе",
        "Оценка на данных, не вошедших в бутстрап выборку",
        "Средняя точность всех деревьев",
        "Метод ускорения обучения"
      ],
      "correct_answer": 1,
      "explanation": "OOB оценка использует около 37% данных, не попавших в бутстрап выборку для каждого дерева, для оценки качества без отдельного тестового набора."
    },
    {
      "question_id": 4,
      "question_text": "Почему в RF обычно используют max_features=sqrt(n_features)?",
      "question_type": "single_choice",
      "options": [
        "Чтобы уменьшить время обучения",
        "Для увеличения разнообразия деревьев",
        "Потому что так точность всегда выше",
        "Это обязательное требование алгоритма"
      ],
      "correct_answer": 1,
      "explanation": "Использование подмножества признаков делает деревья менее похожими, что улучшает качество ансамбля. sqrt(n_features) - хороший эмпирический выбор."
    },
    {
      "question_id": 5,
      "question_text": "Как бороться с переобучением в Random Forest? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Увеличивать количество деревьев",
        "Ограничивать максимальную глубину деревьев",
        "Уменьшать размер бутстрап выборки",
        "Использовать все признаки для каждого дерева"
      ],
      "correct_answers": [1, 2],
      "explanation": "Основные методы: 1) Ограничение глубины деревьев 2) Уменьшение размера бутстрап выборки. Количество деревьев почти не влияет на переобучение."
    },
    {
      "question_id": 6,
      "question_text": "Как вычисляется важность признаков в Random Forest?",
      "question_type": "single_choice",
      "options": [
        "По корреляции с целевой переменной",
        "На основе среднего уменьшения неопределенности (impurity)",
        "С помощью линейных коэффициентов",
        "Только для категориальных признаков"
      ],
      "correct_answer": 1,
      "explanation": "Важность признака - среднее снижение критерия разделения (Джини/энтропии) по всем узлам всех деревьев, где использовался этот признак."
    },
    {
      "question_id": 7,
      "question_text": "В чем отличие ExtraTrees от обычного Random Forest?",
      "question_type": "single_choice",
      "options": [
        "ExtraTrees используют случайные пороги разбиения",
        "ExtraTrees работают только с числовыми признаками",
        "В ExtraTrees нет бутстрап выборок",
        "ExtraTrees дают менее точные предсказания"
      ],
      "correct_answer": 0,
      "explanation": "ExtraTrees (Extremely Randomized Trees) выбирают пороги разбиения случайно, а не ищут оптимальные, что делает их быстрее и иногда устойчивее к шуму."
    },
    {
      "question_id": 8,
      "question_text": "Как количество деревьев влияет на качество Random Forest?",
      "question_type": "single_choice",
      "options": [
        "Больше деревьев всегда значит лучше качество",
        "Качество растет до определенного предела",
        "Оптимальное число деревьев - около 10",
        "Количество деревьев не влияет на качество"
      ],
      "correct_answer": 1,
      "explanation": "Качество улучшается с ростом числа деревьев, но после определенного предела (обычно 100-500) выходит на плато, при этом увеличивается время обучения."
    },
    {
      "question_id": 9,
      "question_text": "Какие преимущества у Random Forest? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Хорошо работает с пропущенными значениями",
        "Требует мало вычислительных ресурсов",
        "Не требует настройки параметров",
        "Устойчив к переобучению на небольших данных"
      ],
      "correct_answers": [0, 3],
      "explanation": "Основные плюсы RF: 1) Умеет работать с пропусками 2) Устойчив к переобучению. Но требует вычислительных ресурсов и настройки параметров."
    },
    {
      "question_id": 10,
      "question_text": "Почему Random Forest плохо экстраполирует за пределы обучающих данных?",
      "question_type": "single_choice",
      "options": [
        "Потому что использует только часть признаков",
        "Деревья дают постоянные предсказания вне обучающего диапазона",
        "Из-за случайного выбора признаков",
        "Потому что требует нормализации данных"
      ],
      "correct_answer": 1,
      "explanation": "Предсказания деревьев (и RF) постоянны в конечных листьях. За пределами обучающего диапазона RF продолжает выдавать предсказания, близкие к граничным значениям."
    }
  ],
  "pdf_links": [
    "https://drive.google.com/file/d/1_LIOLB0bUW4y7MebO8IpKv66kfcwACrj/view?usp=sharing"
  ],
  "metadata": {
    "difficulty_level": "intermediate",
    "tags": ["random_forest", "ensemble", "feature_importance", "bagging"],
    "author": "ML Expert",
    "created_at": "2024-01-25"
  }
}