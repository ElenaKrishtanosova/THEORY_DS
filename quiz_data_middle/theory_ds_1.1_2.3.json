{
  "quiz_title": "Support Vector Machines (SVM)",
  "questions": [
    {
      "question_id": 1,
      "question_text": "Какой тип ядра SVM следует выбрать, если данные визуально разделяются прямой линией?",
      "question_type": "single_choice",
      "options": [
        "Полиномиальное ядро 3-й степени",
        "Гауссово (RBF) ядро",
        "Линейное ядро",
        "Сигмоидное ядро"
      ],
      "correct_answer": 2,
      "explanation": "Для линейно разделимых данных достаточно линейного ядра, так как оно проще и менее склонно к переобучению. Другие ядра избыточны в этом случае."
    },
    {
      "question_id": 2,
      "question_text": "Что произойдет, если установить слишком высокое значение параметра C в SVM?",
      "question_type": "single_choice",
      "options": [
        "Модель станет менее чувствительной к выбросам",
        "Увеличится ширина разделяющей полосы",
        "Модель будет стараться точно классифицировать все тренировочные точки (риск переобучения)",
        "Увеличится скорость обучения"
      ],
      "correct_answer": 2,
      "explanation": "Высокое C уменьшает допустимое количество ошибок классификации на обучающих данных, что может привести к переобучению, особенно на шумных данных."
    },
    {
      "question_id": 3,
      "question_text": "Какое утверждение о support vectors НЕверно?",
      "question_type": "single_choice",
      "options": [
        "Это точки, ближайшие к гиперплоскости",
        "Они полностью определяют положение гиперплоскости",
        "Удаление всех остальных точек не изменит модель",
        "Их всегда меньше, чем точек другого класса"
      ],
      "correct_answer": 3,
      "explanation": "Support vectors могут принадлежать любому классу, их количество не связано с балансом классов. Все остальные утверждения верны."
    },
    {
      "question_id": 4,
      "question_text": "В каком случае SVM с RBF ядром будет плохим выбором?",
      "question_type": "single_choice",
      "options": [
        "Для небольших датасетов с четкими границами классов",
        "Для текстовой классификации с >10K признаков",
        "Для нелинейно разделимых данных с кластерами",
        "Для задач с геометрическими фигурами (круги/эллипсы)"
      ],
      "correct_answer": 1,
      "explanation": "В задачах с высокоразмерными разреженными данными (как текст) линейное ядро обычно работает лучше, а RBF может быть избыточным и медленным."
    },
    {
      "question_id": 5,
      "question_text": "Как параметр gamma в RBF ядре влияет на границу решения?",
      "question_type": "single_choice",
      "options": [
        "Большие gamma делают границу более гладкой",
        "Малые gamma учитывают только ближайшие точки (локальные закономерности)",
        "Gamma не влияет на границу, только на скорость",
        "Оптимальное gamma всегда равно 1/n_features"
      ],
      "correct_answer": 1,
      "explanation": "Малые gamma: дальние точки влияют сильнее → гладкая граница. Большие gamma: только ближайшие точки влияют → сложная, зубчатая граница (риск переобучения)."
    },
    {
      "question_id": 6,
      "question_text": "Почему SVM плохо масштабируется на большие датасеты?",
      "question_type": "single_choice",
      "options": [
        "Из-за необходимости хранить матрицу попарных расстояний",
        "Потому что использует только линейные комбинации",
        "Требует полного перебора всех признаков",
        "Не поддерживает распараллеливание"
      ],
      "correct_answer": 0,
      "explanation": "SVM требует вычисления и хранения матрицы ядер размера n×n (n — число объектов), что становится непрактичным при n > 10^5."
    },
    {
      "question_id": 7,
      "question_text": "Какие два метода можно использовать для ускорения SVM на больших данных?",
      "question_type": "multi_choice",
      "options": [
        "Использовать линейное ядро вместо RBF",
        "Увеличить параметр C",
        "Применить SGDClassifier с hinge loss",
        "Добавить полиномиальные признаки вручную",
        "Использовать выборку опорных векторов (например, LIBSVM)"
      ],
      "correct_answers": [0, 4],
      "explanation": "Линейное ядро вычисляется быстрее и не требует матрицы ядер. Алгоритмы вроде LIBSVM используют оптимизации для работы с подмножествами данных. SGDClassifier — альтернатива, но это уже не классический SVM."
    },
    {
      "question_id": 8,
      "question_text": "Какие утверждения о Soft Margin SVM верны? (Выберите 3)",
      "question_type": "multi_choice",
      "options": [
        "Позволяет некоторым точкам нарушать margin",
        "Использует параметр C для контроля жесткости",
        "Всегда дает лучший результат, чем Hard Margin",
        "Менее чувствителен к выбросам",
        "Требует линейной разделимости данных"
      ],
      "correct_answers": [0, 1, 3],
      "explanation": "Soft Margin: 1) Разрешает ошибки (ξ > 0) 2) C балансирует margin/ошибки 3) Устойчивее к выбросам. Hard Margin лучше при идеальной линейной разделимости, но это редкость на практике."
    },
    {
      "question_id": 9,
      "question_text": "Сопоставьте типы задач с оптимальными ядрами SVM:",
      "question_type": "matching",
      "pairs": {
        "Текстовая классификация": "Линейное ядро",
        "Распознавание сложных форм (например, рукописные цифры)": "RBF ядро",
        "Данные с полиномиальными зависимостями": "Полиномиальное ядро",
        "Мало данных, много шума": "Линейное ядро с большим C"
      },
      "explanation": "1) Текст высокоразмерный и часто линейно разделим. 2) RBF ловит сложные нелинейные границы. 3) Полиномиальное ядро явно учитывает степени. 4) Линейная модель + допуск ошибок (большой C) устойчивее к шуму."
    },
    {
      "question_id": 10,
      "question_text": "Какие шаги обязательны при подготовке данных для SVM? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Нормализация признаков",
        "Удаление всех выбросов",
        "Кодирование категориальных признаков",
        "Обязательное добавление полиномиальных признаков",
        "Балансировка классов через oversampling"
      ],
      "correct_answers": [0, 2],
      "explanation": "SVM чувствителен к масштабу признаков (особенно с RBF), поэтому нормализация обязательна. Категории нужно преобразовать в числовые. Выбросы обрабатываются параметром C, полиномы — опционально, балансировка не всегда нужна."
    }
  ],
  "pdf_links": [
    "https://drive.google.com/file/d/1o4oq2rY_4a-NxzlCHx78otq7akg42TFX/view?usp=sharing",
    "https://drive.google.com/file/d/1tGdjNIJ16dFLoMXcWrcNoEpENgly2-BQ/view?usp=sharing"
  ],
  "metadata": {
    "difficulty_level": "intermediate",
    "tags": ["SVM", "kernel", "hyperparameters", "scalability", "data_preparation"],
    "author": "ML Expert",
    "created_at": "2023-11-20"
  }
}