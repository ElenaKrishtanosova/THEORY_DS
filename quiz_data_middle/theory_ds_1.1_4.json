{
  "quiz_title": "K-nearest neighbour algorithm (KNN)",
  "questions": [
    {
      "question_id": 1,
      "question_text": "Почему KNN называют алгоритмом 'ленивого обучения'?",
      "question_type": "single_choice",
      "options": [
        "Потому что он медленно делает предсказания",
        "Он не строит модель во время обучения, а просто запоминает данные",
        "Он требует меньше настроек, чем другие алгоритмы",
        "Он игнорирует часть данных при обучении"
      ],
      "correct_answer": 1,
      "explanation": "KNN не создает модель во время обучения - он просто хранит все обучающие данные. Все вычисления происходят только при предсказании."
    },
    {
      "question_id": 2,
      "question_text": "Какая метрика расстояния лучше подходит для текстовых данных?",
      "question_type": "single_choice",
      "options": [
        "Евклидово расстояние",
        "Косинусное расстояние",
        "Манхэттенское расстояние",
        "Расстояние Чебышева"
      ],
      "correct_answer": 1,
      "explanation": "Косинусное расстояние хорошо подходит для текста, так как измеряет угол между векторами (сходство направлений), а не абсолютные расстояния."
    },
    {
      "question_id": 3,
      "question_text": "Почему для KNN важно масштабировать признаки?",
      "question_type": "single_choice",
      "options": [
        "Чтобы ускорить работу алгоритма",
        "Чтобы признаки с большими значениями не доминировали",
        "Это требуется только для категориальных признаков",
        "Чтобы уменьшить количество соседей K"
      ],
      "correct_answer": 1,
      "explanation": "Без масштабирования признаки с большим диапазоном значений будут сильнее влиять на расстояние, чем признаки с малым диапазоном."
    },
    {
      "question_id": 4,
      "question_text": "Как выбор значения K влияет на модель? (Выберите 2 верных утверждения)",
      "question_type": "multi_choice",
      "options": [
        "Маленькие K делают границу решения более сложной",
        "Большие K всегда улучшают точность модели",
        "K должно быть больше количества признаков",
        "Обычно выбирают нечетные K для бинарной классификации"
      ],
      "correct_answers": [0, 3],
      "explanation": "Маленькие K приводят к сложным границам (риск переобучения), большие - к сглаживанию. Нечетные K помогают избежать ничьей при бинарной классификации."
    },
    {
      "question_id": 5,
      "question_text": "Какая главная проблема KNN с большим количеством признаков?",
      "question_type": "single_choice",
      "options": [
        "Увеличивается время обучения",
        "Точки становятся примерно равноудаленными (проклятие размерности)",
        "Нельзя использовать категориальные признаки",
        "Требуется больше памяти для хранения модели"
      ],
      "correct_answer": 1,
      "explanation": "В многомерных пространствах все точки оказываются примерно на одинаковом расстоянии, что делает понятие 'ближайших соседей' менее значимым."
    },
    {
      "question_id": 6,
      "question_text": "Какие методы помогают ускорить KNN? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Использование KD-деревьев",
        "Увеличение значения K",
        "Применение PCA для уменьшения размерности",
        "Нормализация всех признаков"
      ],
      "correct_answers": [0, 2],
      "explanation": "KD-деревья ускоряют поиск соседей, PCA сокращает количество признаков. Большие K замедляют предсказание, а нормализация не влияет на скорость."
    },
    {
      "question_id": 7,
      "question_text": "Как обрабатываются категориальные признаки в KNN?",
      "question_type": "single_choice",
      "options": [
        "Их нужно преобразовать в числовые (например, one-hot encoding)",
        "KNN автоматически обрабатывает категориальные признаки",
        "Их следует исключить из модели",
        "Нужно использовать специальные метрики расстояния"
      ],
      "correct_answer": 0,
      "explanation": "Категориальные признаки нужно преобразовать в числовой формат, например через one-hot encoding, чтобы можно было вычислять расстояния."
    },
    {
      "question_id": 8,
      "question_text": "Что делает Weighted KNN?",
      "question_type": "single_choice",
      "options": [
        "Дает больший вес ближайшим соседям",
        "Автоматически выбирает оптимальное K",
        "Учитывает важность каждого признака",
        "Балансирует несбалансированные классы"
      ],
      "correct_answer": 0,
      "explanation": "Weighted KNN присваивает больший вес более близким соседям, уменьшая влияние далеких точек на предсказание."
    },
    {
      "question_id": 9,
      "question_text": "Как выбрать оптимальное K для KNN?",
      "question_type": "single_choice",
      "options": [
        "Всегда брать K=5",
        "Использовать кросс-валидацию",
        "Выбрать K равным количеству классов",
        "Взять максимально возможное K"
      ],
      "correct_answer": 1,
      "explanation": "Оптимальное K выбирают с помощью кросс-валидации, проверяя разные значения на валидационных данных."
    },
    {
      "question_id": 10,
      "question_text": "Какие преимущества у KNN? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Простота реализации и интерпретации",
        "Хорошо работает с большим количеством признаков",
        "Не требует обучения (training phase)",
        "Всегда превосходит другие алгоритмы"
      ],
      "correct_answers": [0, 2],
      "explanation": "KNN прост в понимании и реализации, не требует явного обучения. Но страдает от проклятия размерности и не всегда лучший выбор."
    }
  ],
  "pdf_links": [
    "https://drive.google.com/file/d/10Z7Sszk22ho980dqMUl9T8tViVrqYjBi/view?usp=sharing",
    "https://drive.google.com/file/d/10Z7Sszk22ho980dqMUl9T8tViVrqYjBi/view?usp=sharing",
    "https://drive.google.com/file/d/10Z7Sszk22ho980dqMUl9T8tViVrqYjBi/view?usp=sharing"
  ],
  "metadata": {
    "difficulty_level": "intermediate",
    "tags": ["knn", "distance_metrics", "feature_scaling", "model_selection"],
    "author": "ML Expert",
    "created_at": "2024-02-05"
  }
}