{
  "quiz_title": "Cross-Validation Techniques: Technical Deep Dive",
  "questions": [
    {
      "question_id": 1,
      "question_text": "Почему Holdout метод может давать высокую дисперсию оценок на малых данных?",
      "question_type": "single_choice",
      "options": [
        "Из-за единственного случайного разбиения",
        "Потому что использует все данные для обучения",
        "Из-за стратификации классов",
        "Он всегда дает низкую дисперсию"
      ],
      "correct_answer": 0,
      "explanation": "Holdout использует одно случайное разбиение, что делает оценку неустойчивой на малых данных. K-fold решает эту проблему многократным усреднением."
    },
    {
      "question_id": 2,
      "question_text": "Какое ключевое отличие Stratified K-Fold от обычного K-Fold?",
      "question_type": "single_choice",
      "options": [
        "Сохранение пропорций классов в фолдах",
        "Использование только 50% данных",
        "Обязательное наличие тестового набора",
        "Автоматический подбор гиперпараметров"
      ],
      "correct_answer": 0,
      "explanation": "Stratified K-Fold гарантирует, что соотношение классов в каждом фолде соответствует исходному распределению, что критично для несбалансированных данных."
    },
    {
      "question_id": 3,
      "question_text": "В каких случаях LOOCV (Leave-One-Out) будет предпочтительнее K-Fold? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "При очень малом размере выборки",
        "Когда важна максимальная точность оценки",
        "Для быстрого тестирования моделей",
        "При работе с Big Data",
        "Когда вычислительные ресурсы ограничены"
      ],
      "correct_answers": [0, 1],
      "explanation": "LOOCV дает почти несмещенную оценку на малых данных, но вычислительно дорог. K-Fold - разумный компромисс для больших наборов."
    },
    {
      "question_id": 4,
      "question_text": "Какой метод кросс-валидации наиболее устойчив к выбросам?",
      "question_type": "single_choice",
      "options": [
        "LOOCV",
        "Stratified 5-Fold",
        "Holdout с 50/50 split",
        "Repeated K-Fold"
      ],
      "correct_answer": 3,
      "explanation": "Repeated K-Fold с множественными случайными разбиениями уменьшает влияние выбросов, которые могут попасть в тестовый набор при однократном разбиении."
    },
    {
      "question_id": 5,
      "question_text": "Почему ShuffleSplit не является 'стратифицированным' по умолчанию?",
      "question_type": "single_choice",
      "options": [
        "Он всегда сохраняет пропорции классов",
        "Он не гарантирует баланс классов в разбиениях",
        "Он работает только с регрессией",
        "Это особенность реализации в sklearn"
      ],
      "correct_answer": 1,
      "explanation": "ShuffleSplit делает случайные разбиения без учета распределения классов, в отличие от StratifiedShuffleSplit, который сохраняет баланс."
    },
    {
      "question_id": 6,
      "question_text": "Какое утверждение о временных рядах и кросс-валидации верно?",
      "question_type": "single_choice",
      "options": [
        "TimeSeriesSplit нарушает временной порядок",
        "Обычный K-Fold идеален для временных рядов",
        "TimeSeriesSplit сохраняет хронологию при разбиении",
        "Для временных рядов не нужна валидация"
      ],
      "correct_answer": 2,
      "explanation": "TimeSeriesSplit гарантирует, что тестовые данные всегда идут после обучающих, сохраняя временную зависимость, что критично для временных рядов."
    },
    {
      "question_id": 7,
      "question_text": "Как влияет увеличение K в K-Fold на смещение и дисперсию оценки?",
      "question_type": "single_choice",
      "options": [
        "Уменьшает смещение, увеличивает дисперсию",
        "Увеличивает и смещение, и дисперсию",
        "Уменьшает и смещение, и дисперсию",
        "Не влияет на эти параметры"
      ],
      "correct_answer": 0,
      "explanation": "Большее K (вплоть до LOOCV) уменьшает смещение (оценка ближе к истинной), но увеличивает дисперсию (оценки между фолдами сильнее различаются)."
    },
    {
      "question_id": 8,
      "question_text": "Почему GroupKFold используют при наличии групп в данных?",
      "question_type": "single_choice",
      "options": [
        "Чтобы ускорить вычисления",
        "Для стратификации по нескольким классам",
        "Чтобы одна группа не попала и в train, и в test",
        "Это устаревший метод"
      ],
      "correct_answer": 2,
      "explanation": "GroupKFold гарантирует, что все образцы из одной группы (например, пациент в медицинских данных) попадают только в train или только в test, избегая 'утечки' информации."
    },
    {
      "question_id": 9,
      "question_text": "Какая кросс-валидация лучше для несбалансированных классов?",
      "question_type": "single_choice",
      "options": [
        "Стандартный K-Fold",
        "Stratified K-Fold",
        "Holdout с random split",
        "LOOCV без стратификации"
      ],
      "correct_answer": 1,
      "explanation": "Stratified K-Fold сохраняет соотношение классов в каждом фолде, что особенно важно для редких классов в несбалансированных наборах."
    },
    {
      "question_id": 10,
      "question_text": "Как Repeated K-Fold улучшает обычный K-Fold?",
      "question_type": "single_choice",
      "options": [
        "Уменьшает вычислительную сложность",
        "Делает несколько разных случайных разбиений K-Fold",
        "Автоматически подбирает оптимальное K",
        "Исключает необходимость в тестовом наборе"
      ],
      "correct_answer": 1,
      "explanation": "Repeated K-Fold выполняет обычный K-Fold несколько раз с разными случайными начальными состояниями (random_state), что дает более надежную оценку за счет усреднения."
    }
  ],
  "metadata": {
    "difficulty_level": "advanced",
    "tags": ["Cross-Validation", "K-Fold", "LOOCV", "Stratified", "TimeSeriesSplit", "GroupKFold"],
    "author": "Data Validation Expert",
    "created_at": "2023-11-30"
  }
}