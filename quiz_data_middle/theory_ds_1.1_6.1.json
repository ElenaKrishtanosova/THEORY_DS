{
  "quiz_title": "Dimensionality reduction (Basic understanding)",
  "questions": [
    {
      "question_id": 1,
      "question_text": "Какое основное преимущество PCA перед простым удалением признаков?",
      "question_type": "single_choice",
      "options": [
        "PCA сохраняет большую часть информации в данных",
        "PCA работает быстрее",
        "PCA не требует предварительной обработки данных",
        "PCA лучше интерпретируется"
      ],
      "correct_answer": 0,
      "explanation": "PCA преобразует данные так, что первые несколько компонент содержат большую часть информации, в отличие от простого удаления признаков, которое может терять важную информацию."
    },
    {
      "question_id": 2,
      "question_text": "Когда стоит использовать t-SNE вместо PCA?",
      "question_type": "single_choice",
      "options": [
        "Для визуализации кластеров в данных",
        "Когда нужно быстро обработать большие данные",
        "Для линейного разделения классов",
        "Когда важно сохранить глобальные расстояния"
      ],
      "correct_answer": 0,
      "explanation": "t-SNE лучше подходит для визуализации кластерной структуры данных, так как хорошо сохраняет локальные расстояния между точками."
    },
    {
      "question_id": 3,
      "question_text": "Почему перед PCA нужно масштабировать данные?",
      "question_type": "single_choice",
      "options": [
        "Чтобы алгоритм работал быстрее",
        "Чтобы признаки с большими значениями не доминировали",
        "Это требуется только для категориальных данных",
        "PCA не требует масштабирования"
      ],
      "correct_answer": 1,
      "explanation": "Без масштабирования признаки с большим диапазоном значений будут иметь непропорционально большое влияние на главные компоненты."
    },
    {
      "question_id": 4,
      "question_text": "Какие из этих методов снижения размерности являются supervised? (Выберите 1)",
      "question_type": "single_choice",
      "options": [
        "PCA",
        "LDA",
        "t-SNE",
        "UMAP"
      ],
      "correct_answer": 1,
      "explanation": "LDA (Linear Discriminant Analysis) использует информацию о метках классов, в отличие от других перечисленных unsupervised методов."
    },
    {
      "question_id": 5,
      "question_text": "Как выбрать количество компонент в PCA?",
      "question_type": "single_choice",
      "options": [
        "Всегда брать 2 компоненты для визуализации",
        "Анализировать график объясненной дисперсии",
        "Брать ровно половину от исходного числа признаков",
        "Использовать фиксированное значение 10"
      ],
      "correct_answer": 1,
      "explanation": "График объясненной дисперсии (scree plot) помогает выбрать число компонент, после которого добавление новых компонент мало увеличивает общую объясненную дисперсию."
    },
    {
      "question_id": 6,
      "question_text": "Какие из этих утверждений о UMAP верны? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Работает быстрее t-SNE на больших данных",
        "Сохраняет глобальную структуру данных лучше t-SNE",
        "Всегда дает одинаковый результат при повторном запуске",
        "Требует меньше памяти чем PCA"
      ],
      "correct_answers": [0, 1],
      "explanation": "UMAP быстрее t-SNE и лучше сохраняет глобальную структуру, но результаты могут немного варьироваться между запусками, и он обычно требует больше ресурсов чем PCA."
    },
    {
      "question_id": 7,
      "question_text": "Почему NMF (Non-negative Matrix Factorization) популярен для анализа текстов?",
      "question_type": "single_choice",
      "options": [
        "Он дает интерпретируемые темы с положительными весами слов",
        "Он работает быстрее других методов",
        "Он автоматически определяет число тем",
        "Он не требует предобработки текста"
      ],
      "correct_answer": 0,
      "explanation": "NMF хорошо подходит для текстов, так как представляет темы как комбинации слов с положительными коэффициентами, что упрощает интерпретацию."
    },
    {
      "question_id": 8,
      "question_text": "Какие проблемы могут возникнуть при использовании t-SNE? (Выберите 2)",
      "question_type": "multi_choice",
      "options": [
        "Результаты могут различаться при разных запусках",
        "Плохо масштабируется на большие наборы данных",
        "Всегда дает линейное преобразование",
        "Требует задания меток классов"
      ],
      "correct_answers": [0, 1],
      "explanation": "t-SNE стохастичен (результаты могут варьироваться) и имеет вычислительную сложность O(n²), что делает его медленным для больших данных."
    },
    {
      "question_id": 9,
      "question_text": "Как autoencoder снижает размерность данных?",
      "question_type": "single_choice",
      "options": [
        "Через узкий скрытый слой (bottleneck)",
        "Удаляя наименее важные признаки",
        "С помощью линейных преобразований как PCA",
        "Случайным проецированием данных"
      ],
      "correct_answer": 0,
      "explanation": "Autoencoder вынужден кодировать информацию в сжатом виде в узком промежуточном слое, что приводит к снижению размерности."
    },
    {
      "question_id": 10,
      "question_text": "Какое из этих утверждений о LDA верно?",
      "question_type": "single_choice",
      "options": [
        "LDA максимизирует различие между классами",
        "LDA - это unsupervised метод",
        "LDA всегда лучше PCA для визуализации",
        "LDA не требует нормализации данных"
      ],
      "correct_answer": 0,
      "explanation": "LDA (Linear Discriminant Analysis) - supervised метод, который ищет проекцию, максимально разделяющую классы, и обычно требует нормализации данных."
    }
  ],
  "pdf_links": [
    "https://drive.google.com/file/d/1u16Pq9n2OlXIgDKGzO1AuKLLFvIpInY6/view?usp=sharing",
    "https://drive.google.com/file/d/16KXtU4fgG53mf_z64Ar8ZWNJyrSTkXDf/view?usp=sharing"
  ],
  "metadata": {
    "difficulty_level": "intermediate",
    "tags": ["PCA", "t-SNE", "LDA", "UMAP", "dimensionality_reduction"],
    "author": "AI Tutor",
    "created_at": "2023-11-20"
  }
}